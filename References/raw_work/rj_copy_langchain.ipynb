{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b62edc8-ca0f-4adf-8f4d-1d2458dc0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from LLM_Provider import oai_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b093bd-8f7a-4fd4-9b29-6d176f62300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langgraph.graph import Graph, END\n",
    "import operator\n",
    "from typing import List, Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6349ac07-b240-4c06-8c93-9438846147b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the tool function\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Just evaluates a math expression\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except:\n",
    "        return \"Error in calculation\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e202d54-91c2-422e-bfce-dbb2535f682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the state structure\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[HumanMessage | AIMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "# 3. Create the agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are hired to answer questions. You have access to a calculator tool.\n",
    "    To use the calculator, format your response as:\n",
    "    ACTION: calculator\n",
    "    INPUT: <math expression>\n",
    "    \n",
    "    Otherwise just respond normally. In your response please make sure you respect the following wish from your employer:\n",
    "    DO NOT ASK any questions or wait for a confirmation if they approve of you plan of action. Just give your best answer. \n",
    "    \n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24b658ec-d4f1-4fc6-8ca1-6a312e1fd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ChatOpenAI()\n",
    "agent = prompt | model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c3c98bc-2c84-4b60-9fb4-11857dd68e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x11afda910>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Define the agent function\n",
    "# def run_agent(state: AgentState) -> AgentState:\n",
    "#     messages = state[\"messages\"]\n",
    "#     response = agent.invoke({\"messages\": messages})\n",
    "    \n",
    "#     # Parse response for tool use\n",
    "#     content = response.content\n",
    "#     if \"ACTION: calculator\" in content:\n",
    "#         expression = content.split(\"INPUT:\")[1].strip()\n",
    "#         result = calculator(expression)\n",
    "#         # Add both the tool request and result to messages\n",
    "#         new_messages = list(messages)\n",
    "#         new_messages.extend([\n",
    "#             AIMessage(content=content),\n",
    "#             HumanMessage(content=f\"Calculator result: {result}\")\n",
    "#         ])\n",
    "#         return {\"messages\": new_messages, \"next\": \"agent\"}\n",
    "    \n",
    "#     # No tool use, just continue\n",
    "#     return {\"messages\": messages + [response], \"next\": END}\n",
    "\n",
    "\n",
    "def run_agent(state: AgentState) -> AgentState:\n",
    "    messages = state[\"messages\"]\n",
    "    print(\"Current messages:\", messages)  # Debug logging\n",
    "    response = agent.invoke({\"messages\": messages})\n",
    "    print(\"Agent response:\", response)    # Debug logging\n",
    "    \n",
    "    content = response.content\n",
    "    if \"ACTION: calculator\" in content:\n",
    "        expression = content.split(\"INPUT:\")[1].strip()\n",
    "        print(\"Calculator expression:\", expression)  # Debug logging\n",
    "        result = calculator(expression)\n",
    "        print(\"Calculator result:\", result)         # Debug logging\n",
    "        new_messages = list(messages)\n",
    "        new_messages.extend([\n",
    "            AIMessage(content=content),\n",
    "            HumanMessage(content=f\"Calculator result: {result}\")\n",
    "        ])\n",
    "        return {\"messages\": new_messages, \"next\": \"agent\"}\n",
    "    \n",
    "    return {\"messages\": messages + [response], \"next\": END}\n",
    "\n",
    "def format_output(state: AgentState) -> dict:\n",
    "    \"\"\"Format the final output from the messages\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    return {\"output\": messages[-1].content}\n",
    "\n",
    "workflow = Graph()\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"output\", format_output)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_edge(\"agent\", \"output\")\n",
    "\n",
    "workflow.set_finish_point(\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431b7c17-c4ef-45eb-ab71-5b67d25e0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create the graph\n",
    "# workflow = Graph()\n",
    "# workflow.add_node(\"agent\", run_agent)\n",
    "# workflow.set_entry_point(\"agent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d778ce47-38b6-46c6-b5d2-73e08d8c8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Compile the graph\n",
    "chain = workflow.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28838cdd-faf1-4685-8e4b-965e44cf3cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current messages: [HumanMessage(content='What is 123123 multiplied by 123123123?', additional_kwargs={}, response_metadata={})]\n",
      "Agent response: content='ACTION: calculator\\nINPUT: 123123 * 123123123' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 112, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-adff2a63-286c-4fcc-8275-9d0743e1b959-0' usage_metadata={'input_tokens': 112, 'output_tokens': 15, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Calculator expression: 123123 * 123123123\n",
      "Calculator result: 15159288273129\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 123123 multiplied by 123123123?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe576220-3e53-42fc-8a36-5728aae270db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9c2f1e2-07e6-4bff-9856-385df1dfecd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Calculator result: 15159288273129'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c407923-291a-48f5-bf12-bda45bb8bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123123*123123123==15159288273129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae889291-c81d-4df1-949d-883707fce887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
