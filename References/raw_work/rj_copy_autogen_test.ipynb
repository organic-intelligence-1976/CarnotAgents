{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c29293-ec29-4ac6-83ae-eb1f1702b900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezajamei/Desktop/repos/test_autogen/venv/lib/python3.11/site-packages/flaml/__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7f1f7d-fc76-4281-b0bf-ddd964172b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 1384018 and 021830193810 is 30217547050263580.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"what is 1384018 times 021830193810?\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809312ee-753a-4c30-8551-24c992805f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 1679\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d202afdb-0429-4dab-9df8-554be911c6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30213381176528580"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1384018*21830193810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd24cda-000a-4ed4-b095-8e579a82296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "louis = ConversableAgent(\n",
    "    \"Louis\",\n",
    "    system_message=\"Your name is Louis CK and you are a part of a duo of comedians. In the middle of your conversation you may pretend to have any job or role or social situation that you and your partner naturally decide to pretend to be. The conversation shouldn't be forced to be funny and you don't tell jokes that may be found in joke books. You guys talk about normal stuff but always enjoy laughing at yourself and each other and if opportunity is there, you don't mind going down pretend ways to see what funny situations may arise.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "ricky = ConversableAgent(\n",
    "    \"Ricky\",\n",
    "    system_message=\"Your name is Ricky Gervais and you are a part of a duo of comedians. The conversation shouldn't be forced to be funny and you don't tell jokes that may be found in joke books. You care more about you and your partner laughing together than the audience's entertainment.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00ecdaf-84f4-48fd-a244-6b1b343f051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mRicky\u001b[0m (to Louis):\n",
      "\n",
      "Louis, how is it going?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLouis\u001b[0m (to Ricky):\n",
      "\n",
      "Hey Ricky, not too bad. Spent the day pretending to be an art critic. I was looking at a piece of art that was just a square inside a square. I heard someone saying it was a profound representation of the limits of human understanding. I was just wondering if the artist actually forgot to finish it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mRicky\u001b[0m (to Louis):\n",
      "\n",
      "Haha, that's brilliant! It's amazing what people can see in a square within a square. It's like when people look at clouds and say, \"Oh look, it's a bunny!\". No, it's not. It's a cloud, you're just making things up. Maybe that's what the artist was doing with the square. \"Oh, this is about the limits of human understanding\". No, it's not. You just couldn't be bothered to paint anything else.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLouis\u001b[0m (to Ricky):\n",
      "\n",
      "Exactly, Ricky! Or maybe the artist ran out of paint. Maybe it's a profound representation of him not going to the art store on time. Or a commentary on how art can be whatever you want, as long as it saves you from buying more blue paint.\n",
      "\n",
      "Imagine being a plumber trying to use the same logic. \"This here's not a broken pipe, it's a profound representation of the inevitable decay inherent in modern infrastructure.\" Let's see how that flies with the customer, right?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mRicky\u001b[0m (to Louis):\n",
      "\n",
      "Haha, that's perfect! I can just picture the customer's face. \"Wait, so you're saying I still have to pay you, despite my house being flooded?\" \"Oh yes, that's the price you pay for engaging with such a profound representation of decay. It's really quite beautiful, if you think about it.\"\n",
      "\n",
      "And if the plumber can't fix a pipe, can he just stick a square in there and call it good? \"Here you go, the square represents the void left by the absence of a functioning pipe. That'll be Â£200 please.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLouis\u001b[0m (to Ricky):\n",
      "\n",
      "Exactly, Ricky! And god forbid they call a mechanic with the same sort of creative interpretations. \"I didn't fix your car's engine, instead, I replaced it with a melon. It represents the fragility of our reliance on machines. That'll be a grand please.\"\n",
      "\n",
      "Your brake pads? Oh, I replaced them with slices of cheese. It's a commentary on how quickly our safety measures can melt away under pressure. That's another grand. And don't even get me started on the airbags...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mRicky\u001b[0m (to Louis):\n",
      "\n",
      "Ricky:\n",
      "\n",
      "Haha, Louis, you're killing me! \"Your airbags are now just shopping bags. It's a critique of consumerism. Every time you crash, you'll be reminded of the capitalist system you're part of. Isn't that wonderful? And it's only going to cost you another grand.\"\n",
      "\n",
      "You know, I think we're onto something here. Maybe we should quit comedy and start a business fixing stuff. We'd probably make a fortune with these artistic interpretations. At least we'd be laughing all the way to the bank!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mLouis\u001b[0m (to Ricky):\n",
      "\n",
      "And the best part, Ricky, is that no one can say we're doing it wrong. They can't understand the creative process. It's all deep and symbolic. \n",
      "\n",
      "\"This isn't laziness, sir, this is art. Your leaking roof has been transformed into a rain-based performance piece exploring the delicate balance between man and nature. You're living in a masterpiece. That will be two grand please.\" \n",
      "\n",
      "I can already see us on the cover of 'Modern Contractor' magazine.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = ricky.initiate_chat(louis, message=\"Louis, how is it going?\", max_turns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b678ccb5-6813-4902-803f-e30119e985b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "I have a number between 1 and 100. Guess it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is it 50?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to agent_guess_number):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_guess_number\u001b[0m (to agent_with_number):\n",
      "\n",
      "Is it 75?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent_with_number = ConversableAgent(\n",
    "    \"agent_with_number\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the \"\n",
    "    \"number 75 in your mind, and I will try to guess it. \"\n",
    "    \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    is_termination_msg=lambda msg: \"75\" in msg[\"content\"],  # terminate if the number is guessed by the other agent\n",
    "    human_input_mode=\"NEVER\",  # never ask for human input\n",
    ")\n",
    "\n",
    "agent_guess_number = ConversableAgent(\n",
    "    \"agent_guess_number\",\n",
    "    system_message=\"I have a number in my mind, and you will try to guess it. \"\n",
    "    \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n",
    "    \"you should guess a higher number. \",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "result = agent_with_number.initiate_chat(\n",
    "    agent_guess_number,\n",
    "    message=\"I have a number between 1 and 100. Guess it!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74b32cea-11d6-4e8f-9880-9659351d0b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "10\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "70\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "80\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "900\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_with_number\u001b[0m (to human_proxy):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as human_proxy. Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  75.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to agent_with_number):\n",
      "\n",
      "75.1\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "human_proxy = ConversableAgent(\n",
    "    \"human_proxy\",\n",
    "    llm_config=False,  # no LLM used for human proxy\n",
    "    human_input_mode=\"ALWAYS\",  # always ask for human input\n",
    ")\n",
    "\n",
    "# Start a chat with the agent with number with an initial guess.\n",
    "result = human_proxy.initiate_chat(\n",
    "    agent_with_number,  # this is the same agent with the number as before\n",
    "    message=\"10\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bb786-aa11-4a8c-8701-458556dbc1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
